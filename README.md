# Стек технологий

- **Airflow** – оркестрация ETL  
- **Docker / Docker Compose** – контейнеризация  
- **Python** – обработка данных  
- **Pandas** – фильтрация и агрегация CSV  
- **PostgreSQL** – хранение результатов  
- **Kaggle** – данные с Kaggle  

---

## 1️⃣ Создание `docker-compose.yaml`

Закидываем созданный файл `docker-compose.yaml` в рабочий каталог.

---

## 2️⃣ Запуск контейнеров

Открываем WSL (так как вы на Windows), где установлен Docker, переходим в каталог с `docker-compose.yaml` и выполняем команду:

```bash
docker compose up -d
```

---

## 3️⃣ Подготовка DAG

Пока контейнеры поднимаются, создаем файл `dag.py`(наш DAG).  
После того как контейнеры запустятся, в каталоге с `docker-compose.yaml` появятся четыре каталога: config, dags, logs, plugins
Переместите файл `dag.py` в каталог `dags`.

---

## 4️⃣ Доступ к Airflow

Откройте браузер и в адресной строке введите:

http://localhost:8080


Используйте следующие учетные данные для входа:

- **Логин:** airflow  
- **Пароль:** airflow  

Вы попадёте на стартовую страницу Airflow, где будет доступен ваш DAG из файла `dag.py`.

---

## 5️⃣ Настройка подключения к PostgreSQL

Перед тем как запускать DAG, необходимо создать подключение к базе данных PostgreSQL, которая присутствует в `docker-compose.yaml`.

1. В веб-интерфейсе Airflow нужно перейти в **Admin** и выберать **Connections**.  
2. Нажми синий **+** для добавления нового подключения и заполните поля следующим образом:

| Параметр        | Значение                       |
|-----------------|--------------------------------|
| **Connection Id** | psql_connection               |
| **Connection Type** | Postgres                     |
| **Host**         | host.docker.internal           |
| **Database**     | user                           |
| **Login**        | user                           |
| **Password**     | user                           |
| **Port**         | 5431                           |
| **Extra**        |               |

После сохранения подключения DAG сможет использовать эту базу для загрузки данных.

---

## 6️⃣ Запуск DAG

После настройки подключения к базе данных можно запустить DAG:

1. На странице Airflow найдите ваш DAG (`dag.py`).  
2. Нажмите на **Trigger DAG** (треугольник) в правом верхнем углу страницы.  

DAG начнёт выполняться, и вы сможете отслеживать прогресс и логи задач в интерфейсе.
